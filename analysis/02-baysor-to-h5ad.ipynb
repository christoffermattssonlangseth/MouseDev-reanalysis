{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baysor outputs -> Scanpy h5ad (m20_s31)\n",
    "\n",
    "This notebook scans section folders for Baysor outputs in `m20_s31` and writes one h5ad per section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "\n",
    "sc.settings.verbosity = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure roots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path(\"/Volumes/processing2/nature-dev-mouse-reanalysis/data\")\n",
    "baysor_subdir = \"m20_s31\"\n",
    "\n",
    "out_dir = data_root / \"h5ad\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Baysor outputs (m20_s31)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_dot_underscore(path: Path) -> bool:\n",
    "    return any(part.name.startswith('._') for part in (path, *path.parents))\n",
    "\n",
    "def find_baysor_outputs(root: Path):\n",
    "    outputs = []\n",
    "    for section_dir in sorted(p for p in root.iterdir() if p.is_dir() and p.name.startswith('section_')):\n",
    "        baysor_dir = section_dir / baysor_subdir\n",
    "        if not baysor_dir.exists():\n",
    "            continue\n",
    "        if has_dot_underscore(baysor_dir):\n",
    "            continue\n",
    "        counts_candidates = [\n",
    "            'segmentation_segmentation.csv',\n",
    "            'segmentation.csv',\n",
    "            'segmentation_counts.tsv',\n",
    "            'segmentation.tsv',\n",
    "        ]\n",
    "        counts_path = None\n",
    "        for name in counts_candidates:\n",
    "            p = baysor_dir / name\n",
    "            if p.exists():\n",
    "                counts_path = p\n",
    "                break\n",
    "        stats_path = baysor_dir / 'segmentation_cell_stats.csv'\n",
    "        if counts_path is None or not stats_path.exists():\n",
    "            continue\n",
    "        outputs.append({\n",
    "            'section': section_dir.name,\n",
    "            'dir': baysor_dir,\n",
    "            'counts': counts_path,\n",
    "            'stats': stats_path,\n",
    "        })\n",
    "    return outputs\n",
    "\n",
    "all_outputs = find_baysor_outputs(data_root)\n",
    "print(f\"Found {len(all_outputs)} outputs\")\n",
    "for item in all_outputs:\n",
    "    print(item['dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper: build AnnData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_counts_matrix(counts_path: Path) -> pd.DataFrame:\n",
    "    if counts_path.suffix == '.csv':\n",
    "        df = pd.read_csv(counts_path)\n",
    "        df = df.dropna()\n",
    "        if 'cell' not in df.columns or 'gene' not in df.columns:\n",
    "            raise ValueError('segmentation CSV is missing cell or gene columns')\n",
    "        df['cell'] = df['cell'].astype(str)\n",
    "        df['gene'] = df['gene'].astype(str)\n",
    "        count_mat = pd.crosstab(df['cell'], df['gene'])\n",
    "        return count_mat\n",
    "\n",
    "    df = pd.read_csv(counts_path, sep='\t')\n",
    "    first_col = df.columns[0]\n",
    "    if first_col.lower() in {'gene', 'genes', 'feature', 'features'}:\n",
    "        df = df.set_index(first_col)\n",
    "        var_names = df.index.astype(str)\n",
    "        obs_names = df.columns.astype(str)\n",
    "        X = df.to_numpy().T\n",
    "    else:\n",
    "        df = df.set_index(first_col)\n",
    "        obs_names = df.index.astype(str)\n",
    "        var_names = df.columns.astype(str)\n",
    "        X = df.to_numpy()\n",
    "\n",
    "    return pd.DataFrame(X, index=obs_names, columns=var_names)\n",
    "\n",
    "def load_cell_stats(stats_path: Path) -> pd.DataFrame:\n",
    "    stats = pd.read_csv(stats_path)\n",
    "    if 'cell' not in stats.columns:\n",
    "        raise ValueError('segmentation_cell_stats.csv is missing cell column')\n",
    "    stats['cell'] = stats['cell'].astype(str)\n",
    "    stats = stats.set_index('cell')\n",
    "    return stats\n",
    "\n",
    "def build_adata(counts_path: Path, stats_path: Path):\n",
    "    count_mat = load_counts_matrix(counts_path)\n",
    "    stats = load_cell_stats(stats_path)\n",
    "    stats = stats.reindex(count_mat.index)\n",
    "    adata = sc.AnnData(X=count_mat)\n",
    "    adata.obs = stats\n",
    "    return adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and save h5ad files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_name(name: str) -> str:\n",
    "    return (name\n",
    "            .replace(' ', '_')\n",
    "            .replace('#', ''))\n",
    "\n",
    "for item in all_outputs:\n",
    "    section = item['section']\n",
    "    adata = build_adata(item['counts'], item['stats'])\n",
    "    adata.obs['section'] = section\n",
    "    adata.obs['source_dir'] = str(item['dir'])\n",
    "    out_name = safe_name(section) + '__' + item['dir'].name + '.h5ad'\n",
    "    out_path = out_dir / out_name\n",
    "    print(f'Writing {out_path}...')\n",
    "    adata.write(out_path)\n",
    "\n",
    "out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all exported h5ad files (outer join)\n",
    "h5ad_paths = sorted(p for p in out_dir.glob('*.h5ad') if not p.name.startswith('._'))\n",
    "print(f'Found {len(h5ad_paths)} h5ad files in {out_dir}')\n",
    "adatas = [sc.read_h5ad(p) for p in h5ad_paths]\n",
    "ad_all = sc.concat(adatas, join='outer', merge='unique', label='section', index_unique='-')\n",
    "ad_all\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}